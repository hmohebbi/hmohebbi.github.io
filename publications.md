---
layout: default
title: Publications
permalink: /publications/
---

## Publications

<ui>
<b>DecoderLens: Layerwise Interpretation of Encoder-Decoder Transformers</b>
<br>Anna Langedijk, Hosein Mohebbi, Gabriele Sarti, Willem Zuidema, Jaap Jumelet<br>
<i>In Findings of NAACL</i> 2024<br>
<a href="https://arxiv.org/abs/2310.03686" target="_blank">paper</a>
<br><br>
</ui>

<ui>
<b>Homophone Disambiguation Reveals Patterns of Context Mixing in Speech Transformers</b>
<br>Hosein Mohebbi, Grzegorz Chrupa≈Ça, Willem Zuidema, Afra Alishahi<br>
<span class="emoji">üèÖ</span> <b>Outstanding Paper Award</b><br>
<i>In Proceedings of EMNLP</i> 2023<br>
<a href="https://arxiv.org/abs/2310.09925" target="_blank">paper</a> | <a href="https://github.com/hmohebbi/ContextMixingASR" target="_blank">code</a>
<br><br>
</ui>

<ui>
<b>Quantifying Context Mixing in Transformers</b>
<br>Hosein Mohebbi, Willem Zuidema, Grzegorz Chrupa≈Ça, Afra Alishahi<br>
<i>In Proceedings of EACL</i> 2023<br>
<a href="https://aclanthology.org/2023.eacl-main.245/" target="_blank">paper</a> | <a href="https://github.com/hmohebbi/ValueZeroing" target="_blank">code</a> | <a href="https://hmohebbi.github.io/blog/value-zeroing" target="_blank">blog</a> | <a href="https://huggingface.co/spaces/amsterdamNLP/value-zeroing" target="_blank">demo</a>
<br><br>
</ui>

<ui>
<b>AdapLeR: Speeding up Inference by Adaptive Length Reduction</b>
<br>Ali Modarressi, Hosein Mohebbi, Mohammad Taher Pilehvar<br>
<i>In Proceedings of ACL</i> 2022<br>
<a href="https://aclanthology.org/2022.acl-long.1/" target="_blank">paper</a> | <a href="https://github.com/amodaresi/AdapLeR" target="_blank">code</a> | <a href="http://www.amodarressi.com/AdapLeR/" target="_blank">blog</a> 
<br><br>
</ui>

<ui>
<b>Not All Models Localize Linguistic Knowledge in the Same Place: A Layer-wise Probing on BERToids' Representations</b>
<br>Mohsen Fayyaz, Ehsan Aghazadeh, Ali Modarressi, Hosein Mohebbi, Mohammad Taher Pilehvar<br>
<i>In Proceedings of BlackboxNLP</i> 2021<br>
<a href="https://aclanthology.org/2021.blackboxnlp-1.29/" target="_blank">paper</a>
<br><br>
</ui>

<ui>
<b>Exploring the Role of BERT Token Representations to Explain Sentence Probing Results</b>
<br>Hosein Mohebbi, Ali Modarressi, Mohammad Taher Pilehvar<br>
<i>In Proceedings of EMNLP</i> 2021<br>
<a href="https://aclanthology.org/2021.emnlp-main.61/" target="_blank">paper</a> | <a href="https://github.com/hmohebbi/explain-probing-results" target="_blank">code</a> | <a href="https://hmohebbi.github.io//blog/explain-probing-results" target="_blank">blog</a> 
<br><br>
</ui>
